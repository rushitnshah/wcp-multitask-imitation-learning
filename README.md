## Multitask Imitation Learning
### Rushit N. Shah (2020)
This repository contains the final report I prepared for my qualifying exam (WCP) at University of Illinois, Chicago. The examination was completed in Spring 2020.


### Abstract
Techniques which enable agents to learn from expert demonstrations, also known as imitation learning, have been shown to perform successfully. However, for generalist agents, which must be able to learn to perform multiple different tasks, it may be tedious to learn multiple reward functions for each task separately. In contrast to traditional imitation learning, multitask imitation learning allows an agent to learn multiple reward functions simultaneously, to quickly adapt to a variety of tasks, rather than just one. 

This study takes a closer look at three multitask imitation learning techniques developed over the last decade. These techniques differ significantly from each other in how they address multitask imitation. Additionally, the development of the techniques under review in this study also spans the last decade; this serves to provide a view of this research area as it evolved The incremental changes in approach are also highlighted as these techniques are presented. First an overview of imitation learning is provided. The three techniques considered are then detailed and critiqued, with emphasis on the differences in the approaches and major shortcomings of each. Finally, new research avenues which may lend themselves to the application of multitask imitation learning, are briefly discussed.*
